// StableFluids - A GPU implementation of Jos Stam's Stable Fluids on Unity
// Inspired by https://github.com/keijiro/StableFluids

#pragma kernel AddSource
#pragma kernel GaussSeidel
#pragma kernel Advect
#pragma kernel CreateVelocityField
//#pragma kernel PFinish
//#pragma kernel Jacobi1
//#pragma kernel Jacobi2

// Common parameter
float Time;
float DeltaTime;

// Diffusion
float Diff;
float Alpha;

// External source
float2 SourceOrigin;
float2 SourceStrength;
float SourceDistance; // How far we reach when placing source on an even gradient. 
                      // dist == 0 = SourceStrength. dist >= SourceDistance = 0

// D (density field - smoke)
Texture2D<float4> D_in;
SamplerState samplerD_in;
RWTexture2D<float4> D_out;
SamplerState samplerD_gsbuff;
RWTexture2D<float4> D_gsbuff; // gauss seidel relaxation buffer

// V (velocity field - physical forces)
RWTexture2D<float2> V_in;
SamplerState samplerV_in;

 float3 HUEtoRGB(in float H)
  {
    float R = abs(H * 6 - 3) - 1;
    float G = 2 - abs(H * 6 - 2);
    float B = 2 - abs(H * 6 - 4);
    return saturate(float3(R,G,B));
  }
  
float3 HSVtoRGB(in float3 HSV)
{
    float3 RGB = HUEtoRGB(HSV.x);
    return ((RGB - 1) * HSV.y + 1) * HSV.z;
}

float4 GetColor(float2 pos) {
    float a = SourceOrigin.x - SourceDistance;
    float b = SourceOrigin.x + SourceDistance;
    float spectrumPlacement = saturate((pos.x - a) / (b - a)); // between 0 and 1
    float hue = (spectrumPlacement + Time / 3.) % 1.0; // offset somewhat by time
    float3 rgb = HSVtoRGB(float3(hue, 1.0, 1.0));
    return float4(rgb, 1.0);
    //return float4(hue, 1.0-hue, 0., 1.0);
}

// Add-force step
[numthreads(8, 8, 1)]
//[numthreads(1, 1, 1)]
void AddSource(uint2 tid : SV_DispatchThreadID)
{
    uint2 dim;
    D_out.GetDimensions(dim.x, dim.y); // dimensions will be in pixels of screen / render target
    
    // We want to convert from screen space coordinates to texture space coordinates
    
    float2 pos = (tid + 0.5 - dim * 0.5);
    pos.x /= float(dim.y);
    pos.y /= float(dim.y); // normalize based on both axes, not just height which is what the original implementation did
    
    float2 dist = distance(SourceOrigin, pos);
    
    float amp = max(0, SourceStrength * (1.0 - (dist / SourceDistance)));
    
    float4 color = GetColor(pos);
    //float4 color = float4(0.5, 1., 0., 1.);
    
    // Since we're adding source on top of something,
    // D_out and D_in are probably going to be the same target
    //D_out[tid] = D_in[tid] + amp * color;
    D_out[tid] = D_in[tid] + amp * color;
}

// Our diffusion step
[numthreads(8, 8, 1)]
void GaussSeidel(uint2 tid : SV_DispatchThreadID)
{
    D_out[tid] = (D_in[tid] + Alpha * (
        D_gsbuff[tid - int2(1, 0)]  + 
        D_gsbuff[tid + int2(1, 0)] +
        D_gsbuff[tid - int2(0, 1)] +
        D_gsbuff[tid + int2(0, 1)])
    ) / (1. + 4.*Alpha);
}

[numthreads(8, 8, 1)]
void Advect(uint2 tid : SV_DispatchThreadID) {
    uint2 dim;
    D_out.GetDimensions(dim.x, dim.y); // dimensions will be in pixels of screen / render target
    
    int i, j, i0, j0, i1, j1;
    float x, y, s0, t0, s1, t1;
    
    float dt0 = DeltaTime * dim.y;
    
    x = float(tid.x) - dt0 * V_in[tid].r; // r component - x velocity
    y = float(tid.y) - dt0 * V_in[tid].g; // g component - y velocity
    
    if (x<0.5) x=0.5; if (x>float(dim.x)+0.5) x=float(dim.x)+0.5; i0=(int)x; i1=i0+1; 
    if (y<0.5) y=0.5; if (y>float(dim.y)+0.5) y=float(dim.y)+0.5; j0=(int)y; j1=j0+1; 
    s1 = x-i0; s0 = 1.-s1; t1 = y-j0; t0 = 1.-t1;
    
    D_out[tid] = s0*(t0*D_in[int2(i0,j0)] + t1*D_in[int2(i0,j1)]) + 
                s1*(t0*D_in[int2(i1,j0)] + t1*D_in[int2(i1,j1)]);
    //D_out[tid] = float(tid.x) / dim;     
}


[numthreads(8, 8, 1)]
void CreateVelocityField(uint2 tid : SV_DispatchThreadID) {
    uint2 dim;
    V_in.GetDimensions(dim.x, dim.y); // dimensions will be in pixels of screen / render target
                
    V_in[tid] = float2(tid) / float2(dim);       
}